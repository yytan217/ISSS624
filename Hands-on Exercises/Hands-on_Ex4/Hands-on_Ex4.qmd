---
title: "Hands-on Exercise 4: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method"
editor: visual
---

## Overview

In this hands-on exercise we will learn about **geographically weighted regression (GWR)**. It is a spatial statistical technique that takes non-stationary variables (e.g., climate, demographic, physical environment characteristics) into consideration and models the local relationships between these independent variables and an outcome of interest.

## Getting Started

### The data

2 data sets will be used in this study. They are:

1.  URA Master Plan subzone boundary data;
2.  2015 condo resale data in csv format.

### Setting the tools

We start by ensuring we have all the required R packages installed and loaded. The few key packages used and their purposes as follows:

-   **sf** - spatial data handling

-   **tidyverse**, especially **readr**, **ggplot2** and **dplyr** - attribute data handling

-   **tmap** - choropleth mapping

-   **olsrr** - building OLS and performing diagnostics tests

-   **GWmodel** - calibrating geographical weighted family of models

    Note: **GWModel** provides a collection of localized spatial statistical methods including GW summary statistics, GW principal components analysis (PCA), GW discriminant analysis and various forms of regressions. Commonly, the outputs/parameters are mapped to provide an sophisticated exploratory tool.

-   **coorplot** - multivariate data visualization and analysis

The code chunk below installs and loads these R packages.

```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)
```

## Data Import and Preparation

### Importing geospatial data

The geospatial data to be imported is URA Master Plan 2014's planning subzone boundaries.

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

### Updating CRS information

We use below code chunk to update the newly imported *mpsz* with correct EPSG code 3414.

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
```

We then verify that *mprz_svy21* has the correct EPSG.

```{r}
st_crs(mpsz_svy21)
```

Next, we review the extent of *mpsz_svy21* by using *st_bbox()* of **sf** package.

```{r}
st_bbox(mpsz_svy21)
```

### Importing aspatial data

The aspatial data to be inputted is the 2015 condo resale data.

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
```

We then review the data structure to ensure the data file has been imported correctly.

```{r}
glimpse(condo_resale)
```

```{r}
head(condo_resale$LONGITUDE) #see the data in XCOORD column
```

```{r}
head(condo_resale$LATITUDE) #see the data in YCOORD column
```

```{r}
summary(condo_resale)
```

### Converting aspatial data frame into a sf object

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
```

Notice here we use *st_transform()* to convert the coordinates from wgs84 to svy21.

```{r}
head(condo_resale.sf)
```

## Exploratory Data Analysis

### EDA using statistical graphics

We start with plotting the distribution of *SELLING_PRICE*.

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light green")
```

We see that the distribution is right-skewed, indicating that more condo units were transacted at lower prices. We can normalize the skewed distribution by using log transformation.

```{r}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))
```

we then plot the derived variable *LOG_SELLING_PRICE* to look at the distribution after transformation.

```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light green")
```

We can see that it has moved to a more normal distribution.

### Multiple histogram plots to look at variables distribution

```{r}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="light green")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="light green")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light green")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light green")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```

### Drawing statistical point map

Next, we will look at the geospatial distribution of condominium resale prices in Singapore. We first turn on the interactive model of **tmap**.

```{r}
tmap_mode("view")
```

We then create an interactive point symbol map.

```{r}
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +  
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

Before moving into the next section, we will turn R display into *plot* mode.

```{r}
tmap_mode("plot")
```

## Hedonic Pricing Modelling in R

### Simple linear regression model

We start with building a simple linear regression model by using *SELLING_PRICE* as the dependent variable and *AREA_SQM* as the independent variable.

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

After that, we use *summary()* function to obtain a summary and analysis of variance table.

```{r}
summary(condo.slr)
```

The output shows that *SELLING_PRICE* can be explained by using the formula: y = -258121.1+14719x.

Since p-value is much smaller than 0.001, we will reject the null hypothesis. The simple linear regression model can be used as a good estimator of selling price.

We use below code chunk to visualize the best fit curve on a scatterplot.

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

There are a few outliers with comparatively high selling prices.

### Multiple linear regression method

Before performing cluster analysis, we need to ensure that the cluster variables are not highly correlated. If we use highly correlated variables when building a regression model, the quality of the model will be compromised - **multicollinearity** issue.

We use below code chunk to plot a scatterplot matrix and look at the correlation relationship between the variables.

```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

We can see that **FREEHOLD** is highly correlated to **LEASE_99YEAR**, hence we will exclude **LEASE_99YEAR** in the subsequent model building.

### Building hedonic pricing model using multiple linear regression method

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

Next, we remove variables which are not statistically significant and recalibrate using below code chunk.

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```

### Preparing publication quality table: gtsummary method

Below code chunk is use to create a well formatted regression report.

```{r}
tbl_regression(condo.mlr1, intercept = TRUE)
```

Next, we add the model statistics as a table source note.

```{r}
tbl_regression(condo.mlr1, 
               intercept = TRUE) %>% 
  add_glance_source_note(
    label = list(sigma ~ "\U03C3"),
    include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

#### Checking for multicollinearity

We will use **olsrr** package which provides a list of useful features when building multiple linear regression models such as comprehensive regression output, residual diagnostics, measure of influence etc.

First, we use it to check if there is multicollinearity issue.

```{r}
ols_vif_tol(condo.mlr1)
```

Since the VIF of the independent variables are all less than 10, we can conclude that there is no sign of multicollinearity.

#### Test fo non-linearity

In multiple linear regression, it is important to test the assumption that the linearity and additivy of the relationship between dependent and independent variables.

```{r}
ols_plot_resid_fit(condo.mlr1)
```

We can see that the data points are scattered around the 0 line, there is clear relationships between the independent and dependent variables.

#### Test for normality assumption

```{r}
ols_plot_resid_hist(condo.mlr1)
```

The results show that the residual of the multiple linear regression model resembles a normal distribution.

Alternatively, we can use formal statistical test methods such as below code chunk.

```{r}
ols_test_normality(condo.mlr1)
```

#### Testing of spatial autocorrelation

The hedonic model we are building use geographically referenced attributes, hence it is important for us to visualize the residual of the hedonic pricing model.

We will first convert *condo_resale.sf* into a spatial points data frame. Starting with exporting the residual of the hedonic pricing model, save as data frame then join the newly created data frame with *condo_resale.sf* object.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)
```

Next, we will convert this *condo_resale.res.sf* from simple feature object into a spatial points data frame to feed into **spdep** package.

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

We can use **tmap** package to display the distribution of the residuals on an interactive map

```{r}
tmap_mode("view")
```

```{r}
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

We need to switch back to plot mode before continuing.

```{r}
tmap_mode("plot")
```

The graph plot suggests that there is sign of spatial correlation. We will perform Moran's I test to validate that.

First, we will compute the distance-based matrix.

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

Next, we convert the output neighbors list into a spatial weights.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

Followed by the code chunk for the Moran's I test for residual spatial autocorrelation.

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

Given the p-value is way smaller than the alpha value of 0.05, we will reject the null hypothesis that the residuals are randomly distributed. And since the Observed Moran I \>0, we can infer that the residuals resemble cluster distribution.

## Bulding Hedonic Pricing Models using GWmodel

We will use both fixed and adaptive bandwidth schemes.

### Building fixed bandwidth GWR Model

#### Computing fixed bandwidth

Here we set the argument *adaptive* to FALSE indicating that we intend to compute fixed bandwidth. And we define the stopping rule using *approach* agreement.

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                     FAMILY_FRIENDLY + FREEHOLD, 
                   data=condo_resale.sp, 
                   approach="CV", 
                   kernel="gaussian", 
                   adaptive=FALSE, 
                   longlat=FALSE)
```

#### GWmodel method - fixed bandwidth

We use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + 
                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + 
                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + 
                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + 
                         FAMILY_FRIENDLY + FREEHOLD, 
                       data=condo_resale.sp, 
                       bw=bw.fixed, 
                       kernel = 'gaussian', 
                       longlat = FALSE)
```

The output is saved in a list of class "gwrm".

```{r}
gwr.fixed
```

The report shows adjusted r-square of 0.843, which is much better than the multiple linear regression model of 0.647.

### Building adaptive bandwidth GWR Model

#### Computing the adaptive bandwidth

Now we change the *adaptive* argument to TRUE.

```{r}
bw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + 
                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + 
                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + 
                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                      data=condo_resale.sp, 
                      approach="CV", 
                      kernel="gaussian", 
                      adaptive=TRUE, 
                      longlat=FALSE)
```

#### Constructing the adaptive bandwidth GWR Model

```{r}
gwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + 
                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + 
                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + 
                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                          data=condo_resale.sp, bw=bw.adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE, 
                          longlat = FALSE)
```

And we again look at the output.

```{r}
gwr.adaptive
```

This model also has a higher adjusted r-square comparing to the multiple linear regression model.

### Visualizing GWR output

In addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number, Local R2, residuals, explanatory variable coefficients, and standard errors.

#### Converting SDF into sf data frame

```{r}
condo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%
  st_transform(crs=3414)
```

```{r}
condo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)
condo_resale.sf.adaptive.svy21  
```

```{r}
gwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)
condo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))
```

To display the content of the data frame:

```{r}
glimpse(condo_resale.sf.adaptive)
```

```{r}
summary(gwr.adaptive$SDF$yhat)
```

#### Visualizing local R2

We use below code chunk to create an interactive point symbol map.

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.1) +
tm_shape(condo_resale.sf.adaptive) +  
  tm_dots(col = "Local_R2",
          border.col = "gray60",
          border.lwd = 1) +
  tm_view(set.zoom.limits = c(11,14))
```

#### By URA planning region

```{r}
tm_shape(mpsz_svy21[mpsz_svy21$REGION_N=="CENTRAL REGION", ])+
  tm_polygons()+
tm_shape(condo_resale.sf.adaptive) + 
  tm_bubbles(col = "Local_R2",
           size = 0.15,
           border.col = "gray60",
           border.lwd = 1)
```
